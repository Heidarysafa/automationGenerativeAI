{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fddb73-6678-45ee-a43b-b746c0d83e87",
   "metadata": {},
   "source": [
    "\n",
    "## How to use this notebook:\n",
    "#### Make sure the right version of transformer and pyannote.audio are installed\n",
    "1. install pyannote.audio\n",
    "2. accept the condition on huggingface\n",
    "3. create a read token on hugginface\n",
    "4. request access to the following models in huggingface: \"pyannote/speaker-diarization-3.1\" and \"pyannote/segmentation-3.0\"\n",
    "5. this notebook used ollama with llama3.1 as the LLM. Replace LLM if you want to use LLM with your preferred model/API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95190ddf-cbb4-46de-9eff-0dc2672749fe",
   "metadata": {},
   "source": [
    "### Install Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b229df9-5c3e-445c-b393-d6660ca036ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d80a22c-2780-4a8b-96e3-797db9efa960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44.2\n",
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "import pyannote\n",
    "print(transformers.__version__)\n",
    "print(pyannote.audio.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5bec41-a06b-4720-8c13-95e035ab5a3b",
   "metadata": {},
   "source": [
    "### Step 1: Break the Audio based on the Speakers\n",
    "We use Pyannote models to identify different speakers in the audio file.  \n",
    "This task is called Diarization. Diarization combines speaker segmentation with the task of speaker identification  \n",
    "We use some post-processing to break down the audio to different parts based on speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229b3b15-86ca-4888-ac08-f6a8139e691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=\"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\")\n",
    "\n",
    "# run the pipeline on an audio file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff3faac-29bd-45be-b9e6-f3d203895eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<pyannote.core.annotation.Annotation at 0x13820077af0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diarization = pipeline(\"C:/Users/mojta/Downloads/discussion.mp3\")\n",
    "diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfcaada-9fe9-4ba9-b6a3-fcc736547edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_speaker_segments(diarization):\n",
    "    consolidated_segments = []\n",
    "    current_speaker = None\n",
    "    segment_start = None\n",
    "    \n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        if speaker != current_speaker:\n",
    "            if current_speaker is not None:\n",
    "                # End the current speaker's segment\n",
    "                consolidated_segments.append((current_speaker, segment_start, turn.start))\n",
    "            # Start new speaker's segment\n",
    "            current_speaker = speaker\n",
    "            segment_start = turn.start\n",
    "    \n",
    "    # Append the final speaker's segment\n",
    "    if current_speaker is not None:\n",
    "        consolidated_segments.append((current_speaker, segment_start, turn.end))\n",
    "\n",
    "    return consolidated_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ea83285-dfeb-4bb3-b903-6f20501941f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SPEAKER_01', 0.03096875, 239.57159375),\n",
       " ('SPEAKER_00', 239.57159375, 271.97159375)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = consolidate_speaker_segments(diarization)\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b430b22-ef24-4f49-aa20-1c633dfd003c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b5600bc-7d59-45dc-81d4-aabd7bf52529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def split_audio_segments(audio_file, segments, output_dir='audio_segments'):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(audio_file)\n",
    "\n",
    "    # Iterate over the segments and export each one\n",
    "    for idx, (speaker, start, end) in enumerate(segments):\n",
    "        # Calculate start and end in milliseconds\n",
    "        start_ms = start * 1000\n",
    "        end_ms = end * 1000\n",
    "\n",
    "        # Extract the segment\n",
    "        segment = audio[start_ms:end_ms]\n",
    "\n",
    "        # Create the output file name\n",
    "        speaker_label = speaker.split('_')[-1]  # Get speaker identifier\n",
    "        output_file = os.path.join(output_dir, f\"{idx:02d}_SPEAKER{speaker_label}_START{start:.0f}_STOP{end:.0f}.mp3\")\n",
    "\n",
    "        # Export the segment\n",
    "        segment.export(output_file, format=\"mp3\")\n",
    "        print(f\"Exported {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "489ecb91-f255-4b0d-997c-5ca0b06a8599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported audio_segments\\00_SPEAKER01_START0_STOP240.mp3\n",
      "Exported audio_segments\\01_SPEAKER00_START240_STOP272.mp3\n"
     ]
    }
   ],
   "source": [
    "split_audio_segments('discussion.mp3',segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb1767-2077-4944-9732-c909b4c81036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ac61eaa-104f-41ad-88a5-ef48f2fa9bcd",
   "metadata": {},
   "source": [
    "### Step 2: use Automatic Speech Recognition (ASR)  to turn the segments into text.\n",
    "#### HuggingFace transformer library can be used with a ASR model to perform the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba242a01-c5e3-43d8-addf-092d4e538696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(model=\"facebook/wav2vec2-base-960h\")\n",
    "# stride_length_s is a tuple of the left and right stride length.\n",
    "# With only 1 number, both sides get the same stride, by default\n",
    "# the stride_length on one side is 1/6th of the chunk_length_s\n",
    "#output = pipe(\"D:/long_audio.mp3\", chunk_length_s=10, stride_length_s=(4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecae8a96-879d-4ca7-982f-6a30a00675b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def process_segmented_files(directory='audio_segments'):\n",
    "    # Ensure the directory exists\n",
    "    transcription=\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        raise FileNotFoundError(f\"Directory '{directory}' does not exist.\")\n",
    "    \n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "\n",
    "    # Process each file\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            text = pipe(file_path,chunk_length_s=10, stride_length_s=(4, 2))['text'] # stride is the overlap and chunk is the breakpoints for long audio\n",
    "            num,speaker,time_start,time_stop = file.split('_')\n",
    "            time_stop = time_stop.replace(\".mp3\",'')\n",
    "            \n",
    "            transcription += f\"{speaker}-- {time_start}sec {time_stop}sec:\\n{text}\"\n",
    "            transcription += '\\n\\n'\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b7ee889-5125-4b0d-b219-01404e1a395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcibe = process_segmented_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69c9a9-f3c9-4c34-8597-c37dde019bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b47fddeb-c367-4ac2-a93b-1fd3e7365f55",
   "metadata": {},
   "source": [
    "### Step 3: Extract Information from the transcript of the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d551bc2f-905a-4daa-adc4-8640d268e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "llm =Ollama(base_url ='http://localhost:11434', model ='llama3.1')\n",
    "results = llm.invoke(f\"what are the name on people in this pannel introduction and who is the first person to come to podium?\\n transcription:{transcibe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c75e1454-91e1-4a73-93b1-8e518d76a6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the information you requested:\n",
      "\n",
      "**Panel Introduction:**\n",
      "\n",
      "The panel introduction mentions three speakers:\n",
      "\n",
      "1. **Doctor William Lane Craig**: Research Professor of Philosophy at Talbot School of Theology and Professor of Philosophy at Houston Baptist University.\n",
      "2. **Doctor Rebecca Newberger Goldstein**: American philosopher, novelist, and public intellectual; visiting professor of philosophy at New College of the Humanities in London, England.\n",
      "3. **Doctor George A. Peterson**: Professor of Psychology at the University of Toronto.\n",
      "\n",
      "**Order of Speakers:**\n",
      "\n",
      "The first person to come to the podium is:\n",
      "\n",
      "1. **Doctor William Lane Craig**\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
